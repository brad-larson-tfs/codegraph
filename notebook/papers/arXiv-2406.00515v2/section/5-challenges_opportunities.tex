\section{Challenges \& Opportunities}\label{sec:challenges}
% In the fast-paced world of machine learning, the quest for ever-more powerful models has led to the creation of \done{LLMs}, which have revolutionized the way we approach complex tasks. 
According to our investigations, the LLMs have revolutionized the paradigm of code generation and achieved remarkable performance. 
Despite this promising progress, there are still numerous challenges that need to be addressed. These challenges are mainly caused by the gap between academia and practical development. For example, in academia, the HumanEval benchmark has been established as a de facto standard for evaluating the coding proficiency of LLMs. However, many works have illustrated the evaluation of HumanEval can't reflect the scenario of practical development \cite{jimenez2023swe,du2024evaluating,liu2024your,ding2024crosscodeeval}.
In contrast, these serious challenges offer substantial opportunities for further research and applications. 
In this section, we pinpoint critical challenges and identify promising opportunities, aiming to bridge the research-practicality divide. 

% \textbf{Solving more complex, repository- and software-level code generation.}
\textbf{Enhancing complex code generation at repository and software scale.}
In practical development scenarios, it often involves a large number of complex programming problems of varying difficulty levels \cite{zhang2022automated,li2022competition}. 
While LLMs have shown proficiency in generating function-level code snippets, these models often struggle with more complex, unseen programming problems, repository- and software-level problems that are commonplace in real-world software development.
To this end, it requires strong problem-solving skills in LLM beyond simply functional-level code generation. 
For example, 
% AlphaCode \cite{li2022competition} achieved on average a ranking of top 54.3\% in programming competitions where competitive programming problems require an understanding of algorithms and complex natural language. 
AlphaCode \cite{li2022competition} achieved an average ranking in the top 54.3\% in programming competitions where an understanding of algorithms and complex natural language is required to solve competitive programming problems.
\cite{jimenez2023swe} argues that existing LLMs can't resolve real-world GitHub issues well since the best-performing model, Claude 2, is able to solve a mere 1.96\% of the issues.
The reason for poor performance is mainly attributed to the weak reasoning capabilities \cite{huang2022towards}, complex internal- and external- dependencies \cite{bairi2023codeplan}, and context length limitation of LLMs \cite{bairi2023codeplan}.
Therefore, the pursuit of models that can handle more complex, repository- and software-level code generation opens up new avenues for automation in software development and makes programming more productive and accessible.

% While LLMs have shown proficiency in generating code snippets and solving isolated programming tasks, they often struggle with more complex, multi-file codebase manipulations that are commonplace in real-world software development. This includes understanding the context and dependencies across different parts of a large codebase, version control, and collaborative aspects of software engineering.
% The pursuit of models that can handle repository-level code generation opens up new avenues for automation in software development. To address this, research could focus on creating and training models that understand software at a systemic level, including architecture, design patterns, and software engineering principles. Techniques like graph neural networks, which can model the relationships between different code components, may be instrumental in this regard. Additionally, integrating LLMs with development tools and platforms, such as integrated development environments (IDEs) and version control systems, could further enhance their ability to contribute meaningfully to large-scale software projects.

% \textbf{Alternative model architecture with the structure of code.}
\textbf{Innovating model architectures tuned to code structures.}
Due to their scalability and effectiveness, Transformer-based LLM architectures have become dominant in solving code generation task. 
Nevertheless, they might not be optimally designed to capture the inherent structure and syntax of programming languages (PLs) \cite{guo2020graphcodebert,guo2022unixcoder,ma2022code,kou2023model}. Code has a highly structured nature, with a syntax that is more rigid than natural language. This presents a unique challenge for LLMs, which are often derived from models that were originally designed for natural language processing (NLP).
The development of novel model architectures that inherently understand and integrate the structural properties of code represents a significant opportunity to improve code generation and comprehension. Innovations such as tree-based neural networks \cite{mou2014tbcnn}, which mirror the abstract syntax tree (AST) representation of code, can offer a more natural way for models to learn and generate programming languages. Additionally, leveraging techniques from the compiler theory, such as intermediate representations (IR) \cite{li2022unleashing}, could enable models to operate on a more abstract and generalizable level, making them effective across multiple programming languages \cite{paul2024ircoder}. By exploring architectures beyond the traditional sequential models, researchers can unlock new potentials in code generation.


% However, the inherent syntactic- (e.g., abstract syntax tree (AST)) and semantic-level (e.g., data flow graphs (DFGs)) structure of code are neglected by LLM such that it may only learn a simple translation from natural language descriptions to code snippets.
% Besides, the success of GraphCodeBERT \cite{guo2020graphcodebert} and UniXcoder \cite{guo2022unixcoder} have proven that integrating the structure of code into the model architecture can significantly improve the performance of code-related tasks. 
% % Thus, if we employ a code generation model to conduct code summarization tasks in a zero-shot manner, it may not understand the syntax and logic of code accurately.
% Therefore, we believe that proposing an alternative model architecture of LLM that integrates the structure information of code can further enhance the performance of code generation.  
% dual-pretraining provides a promising solution for handling this. <Code Generation as a Dual-Task of Code Summarization>

% Traditional LLM architectures might not be optimally designed to capture the inherent structure and syntax of programming languages. Code has a highly structured nature, with a syntax that is more rigid than natural language. This presents a unique challenge for LLMs, which are often derived from models that were originally designed for natural language processing.
% The development of novel model architectures that inherently understand and integrate the structural properties of code represents a significant opportunity to improve code generation and comprehension. Innovations such as tree-based neural networks, which mirror the abstract syntax tree representation of code, can offer a more natural way for models to learn and generate programming languages. Additionally, leveraging techniques from the compiler theory, such as intermediate representations, could enable models to operate on a more abstract and generalizable level, making them effective across multiple programming languages. By exploring architectures beyond the traditional sequential models, researchers can unlock new potentials in code generation and analysis.

% \textbf{Acquisition of high-quality code data for pre-training and fine-tuning LLM.}
\textbf{Curating high-quality code data for pre-training and fine-tuning of LLMs.}
% Despite remarkable advances of LLM, information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, decreased information quality issues, have led to hallucinations, and fabricated information. Unreliable information can lead to flawed decisions in businesses, which impacts economic activity. I
The efficacy of LLMs largely depends on the quality and diversity of code datasets used during pre-training and fine-tuning phases \cite{zhou2024lima,kopf2024openassistant,wettig2024qurating}. Currently, there is a scarcity of large, high-quality datasets that encompass a wide range of programming tasks, styles, and languages. This limitation constrains the ability of LLMs to generalize across unseen programming tasks, different coding environments, and real-world software development scenarios.
The development of more sophisticated data acquisition techniques, such as automated code repositories mining \cite{linstead2007mining}, advanced filtering algorithms, and code data synthesis \cite{liu2024best} (see Section \ref{sec:data_synthesis}), can lead to the creation of richer datasets. Collaborations with industry partners (e.g., GitHub) could also facilitate access to proprietary codebases, thereby enhancing the practical relevance of the training material. Furthermore, the adoption of open-source models for dataset sharing can accelerate the collective effort to improve the breadth and depth of code data available for LLM research.

% \textbf{Comprehensive benchmarks and metrics to evaluate the coding capability of LLM.}
\textbf{Developing comprehensive benchmarks and metrics for coding proficiency evaluation in LLMs.}
% aligning with practical development scenario.
Current benchmarks like HumanEval may not capture the full spectrum of coding skills required for practical software development \cite{ni2023l2ceval}. Additionally, metrics often focus on syntactic correctness or functional accuracy, neglecting aspects such as code efficiency \cite{peitek2021program}, style \cite{chen2023duetcs}, readability \cite{buse2009learning}, or maintainability \cite{ardito2020tool}.
The design of comprehensive benchmarks that simulate real-world software development challenges could provide a more accurate assessment of LLMs' coding capabilities. These benchmarks should include diverse programming tasks of varying difficulty levels, such as debugging \cite{zhong2024ldb}, refactoring \cite{shirafuji2023refactoring}, and optimization \cite{ishida2024langprop}, and should be complemented by metrics that evaluate qualitative aspects of code. The establishment of community-driven benchmarking platforms could facilitate continuous evaluation and comparison of LLMs for code generation across the industry and academia.

% \textbf{Low-resource, low-level, and domain-specific programming languages.}
\textbf{Support for low-resource, low-level, and domain-specific programming languages.}
% In NLP, human languages are categorized into high-, middle-, and low-resource languages based on the amount of available data in each language. High-resource languages such as English are extensively studied, while low-resource languages such as Swahili and Yoruba often rely on transfer learning from other languages to improve performance due to data scarcity. 
LLMs are predominantly trained in popular high-level programming languages, leaving low-resource, low-level, and domain-specific languages underrepresented. This lack of focus restricts the applicability of LLMs in certain specialized fields and systems programming \cite{thakur2023benchmarking}.
Intensifying research on transfer learning and meta-learning approaches may enable LLMs to leverage knowledge from high-resource languages to enhance their performance on less common ones \cite{chen2022transferability,cassano2023knowledge}. 
Additionally, partnerships with domain experts can guide the creation of targeted datasets and fine-tuning strategies to better serve niche markets. The development of LLMs with a capacity for multilingual code generation also presents a significant opportunity for broadening the scope of applications.

% \textbf{Coding knowledge updates and continuing programming learning.}
\textbf{Continuous learning for LLMs to keep pace with evolving coding knowledge.}
% with programming documentation.
The software development landscape is continuously evolving, with new languages, frameworks, and best practices emerging regularly. LLMs risk becoming outdated if they cannot adapt to these changes and incorporate the latest programming knowledge \cite{jang2022towards,wang2023knowledge}.
While retrieval augmented code generation mitigates these issues, the performance is limited by the quality of the retrieval context 
While retrieval-augmented code generation offers a partial solution to these issues, its effectiveness is inherently constrained by the quality of retrieved context.
\cite{lu2022reacc,zhou2022docprompting,zhang2023repocoder}. 
Therefore, establishing mechanisms for continuous learning and updating of LLMs can help maintain their relevance over time. This could involve real-time monitoring of code repositories to identify trends and innovations, as well as the creation of incremental learning systems that can assimilate new information without forgetting previously acquired knowledge. Engaging the LLMs in active learning scenarios where they interact with human developers may also foster ongoing knowledge acquisition.


% \textbf{Code safety and alignment learning for human preferences.}
\textbf{Ensuring code safety and aligning LLM outputs with human coding preferences.}
Ensuring the safety and security of code generated by LLMs is a paramount concern, as is their ability to align with human preferences and ethical standards. Current models may inadvertently introduce vulnerabilities or generate code that does not adhere to desired norms \cite{chen2021evaluating,yang2024robustness}.
Research into the integration of formal verification tools within the LLM pipeline can enhance the safety of the produced code. Additionally, developing frameworks for alignment learning that capture and reflect human ethical preferences can ensure that the code generation process aligns with societal values \cite{ouyang2022training,qi2023fine}. Transparent and explainable AI methodologies can also contribute to building trust in the LLM-generated code by making the decision-making process more accessible to developers.