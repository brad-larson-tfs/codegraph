\begin{table}[t] 
% \begin{wraptable}{R}{0.5\linewidth}
\caption{\done{The performance improvement of instruction-tuned models over their pretrained counterparts on the HumanEval, MBPP, and BigCodeBench benchmarks. 
The last two rows demonstrate the average improvement on the first two benchmarks and the three benchmarks, respectively.
}
}
\label{tab:instruct_improve}
\centering
\scalebox{0.8}{
\rotatebox{0}{
    \begin{tabular}{lccccc}
    \toprule
    & \textbf{\makecell[c]{Qwen2.5-Coder-\\Instruct 7B}} & \textbf{\makecell[c]{StarCoder2-\\Instruct 15.5B}} & \textbf{\makecell[c]{CodeGemma-\\Instruct 7B}} & \textbf{\makecell[c]{DeepSeek-Coder-\\Instruct 33B}} & \textbf{\makecell[c]{Code Llama-\\Instruct 70B}} \\ 
\midrule
    \textbf{HumanEval} & 43.51\% & 56.80\% & 26.07\% & 41.35\% & 27.92\% \\
    \textbf{MBPP} & 8.58\% & 13.60\% & \cellcolor{gray!15}-3.56\% & 6.06\% & \cellcolor{gray!15}-0.32\% \\
    \textbf{BigCodeBench} & - & 17.45\% & 2.61\% & 9.66\% & 12.73\% \\
    \midrule
    \textbf{\# Avg. Imp. H. M.} & 26.04\% & 35.20\% & 11.26\%  & 23.71\% & 13.80\% \\
    \textbf{\# Avg. Imp. H. M. B.} & - & 29.28\% & 8.37\% & 19.02\% & 13.44\% \\
    \bottomrule
    \end{tabular}
}
}
% \end{wraptable}
\end{table}